import faiss
import numpy as np
import json
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from config import OPENAI_API_KEY, OPENAI_BASE_URL

from langchain.schema import Document  # å¯¼å…¥ Document ç±»

class KnowledgeBase:
    def __init__(self, data_file="data/documents.json"):
        self.data_file = data_file
        self.documents = self.load_documents()
        self.index = self.create_faiss_index()

    def load_documents(self):
        """ä» JSON æ–‡ä»¶åŠ è½½æ–‡æ¡£"""
        with open(self.data_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("documents", [])  # ç¡®ä¿è¿”å›åˆ—è¡¨ï¼Œé¿å… NoneType é”™è¯¯

    def create_faiss_index(self):
        """åˆ›å»º FAISS å‘é‡ç´¢å¼•"""
        embeddings = OpenAIEmbeddings(
            model="text-embedding-v3",
            openai_api_key=OPENAI_API_KEY,
            openai_api_base=OPENAI_BASE_URL
        )

        texts = [doc.get("content", "").strip() for doc in self.documents if isinstance(doc.get("content"), str)]
        print("ğŸš€ Embedding è¾“å…¥æ–‡æœ¬:", texts)  # Debug

        # ğŸ”´ ç¡®ä¿ texts éç©º
        if not texts:
            raise ValueError("âŒ æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºåµŒå…¥å‘é‡")

        print("âœ… é¢„å¤„ç†åçš„æ–‡æœ¬:", texts)

        try:
            # æ‹†åˆ†æ–‡æœ¬
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)
            docs = text_splitter.create_documents(texts)  # è¿™é‡Œè¿”å›çš„æ˜¯ Document ç±»å‹çš„åˆ—è¡¨

            print("ğŸ“Œ ä¼ å…¥ OpenAI API çš„æ–‡æœ¬æ®µæ•°é‡:", len(docs))
            for i, d in enumerate(docs[:5]):  # ä»…æ‰“å°å‰ 5 æ®µï¼Œé˜²æ­¢è¿‡é•¿
                print(f"ğŸ“œ ç¬¬ {i+1} æ®µ:", d.page_content)

            # å‘é€ç»™ OpenAI
            vector_store = FAISS.from_documents(docs, embeddings)  # è¿™é‡Œ docs å·²ç»æ˜¯ Document ç±»å‹

        except Exception as e:
            print("âŒ OpenAI å¤„ç†å¤±è´¥:", e)
            raise e  # æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢ç¨‹åº

        return vector_store

    def search(self, query, top_k=3):
        """åœ¨ FAISS ç´¢å¼•ä¸­æŸ¥æ‰¾æœ€ç›¸å…³çš„æ–‡æ¡£"""
        results = self.index.similarity_search(query, k=top_k)
        return [r.page_content for r in results]

kb = KnowledgeBase()

